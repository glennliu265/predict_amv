{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_moc = xr.open_dataset(\"../CESM_data/CESM1LE_MOC_NAtl_20N-50N_19200101_20051201.nc\")\n",
    "\n",
    "ds_sst = xr.open_dataset(\"../CESM_data/CESM1LE_sst_NAtl_19200101_20051201.nc\")['sst'][21:54,:,:,:]\n",
    "#ds_FLNS = xr.open_dataset(\"../CESM_data/CESM1LE_FLNS_NAtl_19200101_20051201.nc\")['FLNS'][21:54,0:89,:,:]\n",
    "#ds_FSNS = xr.open_dataset(\"../CESM_data/CESM1LE_FSNS_NAtl_19200101_20051201.nc\")['FSNS'][21:54,0:89,:,:]\n",
    "#ds_LHFLX = xr.open_dataset(\"../CESM_data/CESM1LE_LHFLX_NAtl_19200101_20051201.nc\")['LHFLX'][21:54,0:89,:,:]\n",
    "#ds_NHFLX = xr.open_dataset(\"../CESM_data/CESM1LE_NHFLX_NAtl_19200101_20051201.nc\")['NHFLX'][21:54,0:89,:,:]\n",
    "#ds_SHFLX = xr.open_dataset(\"../CESM_data/CESM1LE_SHFLX_NAtl_19200101_20051201.nc\")['SHFLX'][21:54,0:89,:,:]\n",
    "ds_sss = xr.open_dataset(\"../CESM_data/CESM1LE_sss_NAtl_19200101_20051201.nc\")['sss'][21:54,0:89,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deseason(ds):\n",
    "    data = ds.T.values\n",
    "    monthly_means = np.zeros((42,86,12,89,33))\n",
    "    \n",
    "    iyr = 0\n",
    "    for it in range(1032):\n",
    "        mo_ind = it%12\n",
    "        monthly_means[:,iyr,mo_ind,:,:] = data[:,it,:,:]\n",
    "        if mo_ind==11:\n",
    "            iyr+=1\n",
    "    monthly_means = np.nanmean(monthly_means,axis=1)\n",
    "    \n",
    "    data_deseason = np.zeros(data.shape)\n",
    "    for it in range(1032):\n",
    "        mo_ind = it%12\n",
    "        data_deseason[:,it,:,:] = data[:,it,:,:] - monthly_means[:,mo_ind,:,:]\n",
    "    \n",
    "    data_deseason[np.isnan(data_deseason)] = 0\n",
    "    return data_deseason\n",
    "\n",
    "def deseason_amoc(arr):\n",
    "    \n",
    "    monthly_means = np.zeros((42,86,12))\n",
    "    \n",
    "    iyr = 0\n",
    "    for it in range(1032):\n",
    "        mo_ind = it%12\n",
    "        monthly_means[:,iyr,mo_ind] = arr[:,it]\n",
    "        if mo_ind==11:\n",
    "            iyr+=1\n",
    "    monthly_means = np.nanmean(monthly_means,axis=1)\n",
    "    \n",
    "    data_deseason = np.zeros(arr.shape)\n",
    "    for it in range(1032):\n",
    "        mo_ind = it%12\n",
    "        data_deseason[:,it] = arr[:,it] - monthly_means[:,mo_ind]\n",
    "    \n",
    "    data_deseason[np.isnan(data_deseason)] = 0\n",
    "    return data_deseason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_deseasoned = deseason(ds_sst)\n",
    "#FLNS_deseasoned = deseason(ds_FLNS)\n",
    "#FSNS_deseasoned = deseason(ds_FSNS)\n",
    "#LHFLX_deseasoned = deseason(ds_LHFLX)\n",
    "#NHFLX_deseasoned = deseason(ds_NHFLX)\n",
    "#SHFLX_deseasoned = deseason(ds_SHFLX)\n",
    "sss_deseasoned = deseason(ds_sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amoc = ds_moc['MOC'][:,:,:,:,0:24].sum(dim='moc_comp').max(dim=('moc_z','lat_aux_grid')).values\n",
    "amoc_deseasoned = deseason_amoc(amoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_normed = (sst_deseasoned - np.mean(sst_deseasoned))/np.std(sst_deseasoned)\n",
    "sss_normed = (sss_deseasoned - np.mean(sss_deseasoned))/np.std(sss_deseasoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(sst_normed,axis=(0,2,3)))\n",
    "plt.plot(np.mean(sss_normed,axis=(0,2,3)))\n",
    "\n",
    "plt.legend(['sst','sss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(sst_deseasoned,axis=(0,2,3)))\n",
    "#plt.plot(np.mean(FLNS_deseasoned,axis=(0,2,3)))\n",
    "#plt.plot(np.mean(FSNS_deseasoned,axis=(0,2,3)))\n",
    "#plt.plot(np.mean(LHFLX_deseasoned,axis=(0,2,3)))\n",
    "#plt.plot(np.mean(NHFLX_deseasoned,axis=(0,2,3)))\n",
    "#plt.plot(np.mean(SHFLX_deseasoned,axis=(0,2,3)))\n",
    "plt.plot(np.mean(sss_deseasoned,axis=(0,2,3)))\n",
    "\n",
    "#plt.legend(['sst','FLNS','FSNS','LHFLX','NHFLX','SHFLX','sss'])\n",
    "plt.legend(['sst','sss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_deseasoned = np.array( [sst_deseasoned,FLNS_deseasoned,\n",
    "#                             FSNS_deseasoned,LHFLX_deseasoned,\n",
    "#                             NHFLX_deseasoned,SHFLX_deseasoned,sss_deseasoned] )\n",
    "\n",
    "data_normed = np.array( [sst_normed,sss_normed] )\n",
    "channels = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead = 12\n",
    "tstep = 1032\n",
    "\n",
    "y = np.mean(sst_normed[:,lead:,:,:],axis=(2,3)).reshape((tstep-lead)*42,1)   # predict SST\n",
    "#y = amoc_deseasoned[:,lead:].reshape((tstep-lead)*42,1)                           # predict AMOC\n",
    "X = data_normed[:,:,0:tstep-lead,:,:].reshape(channels,(tstep-lead)*42,33,89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_ind = np.arange(0,42*(tstep-lead),1)\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(shuffled_ind)\n",
    "X_shuffled =  np.transpose(X[:,shuffled_ind,:,:],(1,0,2,3)).astype(np.float32)\n",
    "y_shuffled =  y[shuffled_ind].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_train = 0.8\n",
    "\n",
    "X_train = torch.from_numpy( X_shuffled[0:int(np.floor(percent_train*(tstep-lead)*42)),:,:,:] )\n",
    "y_train = torch.from_numpy( y_shuffled[0:int(np.floor(percent_train*(tstep-lead)*42)),:] )\n",
    "\n",
    "X_val = torch.from_numpy( X_shuffled[int(np.floor(percent_train*(tstep-lead)*42)):,:,:,:] )\n",
    "y_val = torch.from_numpy( y_shuffled[int(np.floor(percent_train*(tstep-lead)*42)):,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pts = np.mean(X_shuffled[:,0,:,:],axis=(1,2))\n",
    "x2_pts = np.mean(X_shuffled[:,1,:,:],axis=(1,2))\n",
    "y_pts = y_shuffled\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "sc = plt.scatter(x1_pts,x2_pts,c=y_pts,vmin=-1,vmax=1,cmap='RdBu_r',s=20,alpha=0.8)\n",
    "plt.colorbar(sc,label='future SST')\n",
    "plt.ylim([-1.2,1.2])\n",
    "plt.xlim([-1.2,1.2])\n",
    "plt.xlabel('basin avg SST')\n",
    "plt.ylabel('basin avg SSS')\n",
    "plt.title('future SST leads '+str(lead)+' month(s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pts = np.mean(X_train[:,0,:,:].numpy(),axis=(1,2))\n",
    "x2_pts = np.mean(X_train[:,1,:,:].numpy(),axis=(1,2))\n",
    "y_pts = y_train.numpy()\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "sc = plt.scatter(x1_pts,x2_pts,c=y_pts,vmin=-1,vmax=1,cmap='RdBu_r',s=20,alpha=0.8)\n",
    "plt.colorbar(sc,label='future SST')\n",
    "plt.ylim([-1.2,1.2])\n",
    "plt.xlim([-1.2,1.2])\n",
    "plt.xlabel('basin avg SST')\n",
    "plt.ylabel('basin avg SSS')\n",
    "plt.title('future SST leads '+str(lead)+' month(s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv2d(in_channels=channels, out_channels=32, kernel_size=5),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=5),\n",
    "                      \n",
    "          #nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
    "          #nn.ReLU(),\n",
    "          #nn.MaxPool2d(kernel_size=3),\n",
    "                      \n",
    "          nn.Flatten(),\n",
    "          nn.Linear(in_features=5*17*32,out_features=128),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(in_features=128,out_features=64),\n",
    "          nn.ReLU(),\n",
    "          \n",
    "          nn.Dropout(p=0.5),\n",
    "          nn.Linear(in_features=64,out_features=1))\n",
    "\n",
    "opt = torch.optim.Adadelta(model.parameters())\n",
    "#opt = torch.optim.SGD(model.parameters(),lr = 1e-4)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(X_train)\n",
    "before_train = loss_fn(y_pred.squeeze(), y_train.squeeze())\n",
    "print('Test loss before training' , before_train.item())\n",
    "plt.plot(y_pred.detach().numpy(),y_train.numpy(),'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "\n",
    "epo_losses = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in tqdm(range(epoch)):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Compute Loss\n",
    "    loss = loss_fn(y_pred.squeeze(), y_train.squeeze())\n",
    "    epo_losses.append(loss.item())\n",
    "    \n",
    "    # update\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epo_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(X_train)\n",
    "after_train = loss_fn(y_pred, y_train) \n",
    "print('Test loss after Training' , after_train.item())\n",
    "plt.plot(y_pred.detach().numpy(),y_train.numpy(),'.')\n",
    "plt.plot([-0.5,0.5],[-0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
