#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""

Visualize output generated by "LRP_FNN.py"

Copied sections over from above script on 2022.10.10
Also copied from LRP_test.ipynb on the same date...

Created on Mon Oct 10 14:51:33 2022

@author: gliu

"""

import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import numpy as np
import time
import sys

from tqdm import tqdm
import matplotlib.ticker as tick

#%% User Edits

# -------------------
# Data settings
# -------------------
regrid      = None
detrend     = 0
ens         = 40
tstep       = 86

# -------------------
# Indicate paths
# -------------------
datpath = "../../CESM_data/"
if regrid is None:
    modpath = datpath + "Models/FNN2_quant0_resNone/"
else:
    modpath = datpath + "Models/FNN2_quant0_res224/"
figpath = "/Users/gliu/Downloads/02_Research/01_Projects/04_Predict_AMV/02_Figures/20221014/"
outpath = datpath + "Metrics/"

# -------------------
# Modules
# -------------------
sys.path.append("/Users/gliu/Downloads/02_Research/01_Projects/01_AMV/00_Commons/03_Scripts/")
from amv import viz
# Load modules (LRPutils by Peidong)
sys.path.append("/Users/gliu/Downloads/02_Research/01_Projects/04_Predict_AMV/03_Scripts/scrap/")
sys.path.append("/Users/gliu/Downloads/02_Research/01_Projects/04_Predict_AMV/03_Scripts/predict_amv/")
import LRPutils as utils
import amvmod as am

# ----------------
# Settings for LRP
# ----------------
gamma       = 0.25
epsilon     = 0.25 * 0.36 # 0.36 is 1 stdev of the AMV Index

# -------------------
# Training Parameters
# -------------------
runs        = np.arange(1,11,1)
leads       = np.arange(0,24+3,3)
thresholds  = [-1,1]
nruns,nleads,nthres = len(runs),len(leads),len(thresholds)+1,

# -------------------
# Plot Settings
# -------------------
proj            = ccrs.PlateCarree()
vnames          = ("SST","SSS","SLP")
thresnames      = ("AMV+","Neutral","AMV-",)
cmnames_long    = ("True Positive","False Positive","False Negative","True Positive")
scale_relevance = True # Set to True to scale relevance values for each sample to be betweeen -1 and 1 after compositing
plot_composites = False


# -------------------
# Load Lat/Lon
# -------------------
lat2 = np.load("%slat_2deg_NAT.npy"% (datpath))
lon2 = np.load("%slon_2deg_NAT.npy"% (datpath))

# -------------------------------------------------------------------------
# Load data normalization factors (see prepare_training_validation_data.py)
# -------------------------------------------------------------------------
vmeans,vstdevs = np.load(datpath+"CESM_nfactors_detrend0_regridNone.npy") # [Mean,Stdev][SST,SSS,SLP]
#%% Load the data

"""
The content of each entry in the dict:
    relevances [run x threshold] --> [sample x channel x lat x lon] : Samplewise LRP values
    ids        [run x threshold] --> [sample]                       : Indices of each sample
    y_pred     [run x threshold] --> [sample]                       : Predicted y-values
    y_targ     [sample x 1]                                         : Actual class # (AMV Class)
    y_val      [sample x 1]                                         : Actual y values (AMV Index)

Remaining entries are just single values indicating the values

"""


#lead     = 24

for lead in np.arange(3,24,3): # (0,24+3,3)
    # Load the relevance data for a given leadtime...
    st       = time.time()
    savename = "%sLRPout_lead%02i_gamma%.3f_epsilon%.3f.npz" % (outpath,lead,gamma,epsilon)
    npz      = np.load(savename,allow_pickle=True)
    ndict    = [npz[z] for z in npz.files]
    relevances,ids,y_pred,y_targ,y_val,lead,gamma,epsilon,allow_pickle=ndict
    print("Loaded data in %.2fs"% (time.time()-st))
    
    
    # Prepare Lat/Lon
    _,nvar,nlat,nlon = relevances[0,0].shape # Get dimensions
    lat  =  np.linspace(lat2[0],lat2[-1],nlat)
    lon  = np.linspace(lon2[0],lon2[-1],nlon)
    
    
    # Load y predictions back into an array of the same size
    """
    ** NOTE: Modify LRP processing script to this step can be avoided...
    """
    y_pred_new = np.zeros( (nruns,)+y_val.shape) * np.nan # [Model x Samples x 1]
    for r in range(nruns):
        for th in range(3):
            ithres               = ids[r,th]
            y_pred_new[r,ithres,0] = y_pred[r,th].numpy()
    
    # Load and retrieve data for the given lead time
    if regrid is None:
        data   = np.load(datpath+ "CESM_data_sst_sss_psl_deseason_normalized_resized_detrend%i_regrid%s.npy" % (detrend,regrid)) # [variable x ensemble x year x lon x lat]
    else:
        data   = np.load(datpath+ "CESM_data_sst_sss_psl_deseason_normalized_resized_detrend%i.npy" % (detrend)) # [variable x ensemble x year x lon x lat]
    X = (data[:,:ens,:tstep-lead,:,:]).reshape(3,ens*(tstep-lead),nlat,nlon).transpose(1,0,2,3)
    nsamples = X.shape[0]
    landmask = np.abs(X[0,:,:,:].sum(0)) < 1e-6
    mask = np.ones(landmask.shape) 
    mask[landmask] = np.nan
    
    # # Reindex the relevances to the original sample dimensions
    # """
    # ** NOTE: Modify LRP processing script to move this step there...
    # *** NOTE: Some is wrong with the current block --> indexed portion
    # is not saving through each loop..
    # """
    # st = time.time()
    # relevances_new = np.zeros((nruns,nthres,nsamples,nvar,nlat,nlon)) * np.nan
    # for r in tqdm(range(nruns)):
    #     for th in range(nthres):
    #         idsel = ids[r,th]
    #         # print(relevances[r,th].shape)
    #         # print(relevances_new[r,th,idsel,:,:,:].shape)
    #         relevances_new[r,th,idsel,:,:,:] = relevances[r,th].copy()
    #         # print(relevances[r,th])
    #         # print(relevances_new[r,th,idsel,:,:,:])
    # print("Reindexed relevances in %.2fs" % (time.time()-st))
            
    
    #%% Compute confusion matrices
    
    # Preallocate for confusion matrices
    # cm_ids     = np.empty((3,2,2,nsamples),dtype='object')# Confusion matrix Boolean indices [Class,Actual_class,Pred_class,Indices]
    # cm_counts  = np.empty((3,2,2),dtype='object') # Counts of predicted values for each      [Class,Actual_class,Pred_class]
    # cm_totals  = cm_counts.copy() # Total count (for division)
    # cm_acc     = cm_counts.copy() # Accuracy values
    # cm_names   = ["TP","FP","FN","TN"] # Names of each
    
    # Compute the accuracy of each prediction
    cmids_all    = [] # [run][Class,Confmat_quadrant,Indices]
    cmcounts_all = [] # [run][Class,Confmat_quadrant,Pred_class]
    cmtotals_all = [] #
    for r in range(nruns):
        cm_ids,cm_counts,cm_totals,cm_acc,cm_names = am.calc_confmat_loop(y_pred_new[r,...],y_targ)
        cmids_all.append(cm_ids)
        cmcounts_all.append(cm_counts)
        cmtotals_all.append(cm_totals)
    
    # #%%
    # """
    # # Blind Composite (Just composite all values of 1 class, regardless of result)
    # """
    # # Check how different the composite relevances are for each model
    # composite_relevances = np.zeros((nruns,nthres,nvar,nlat,nlon))
    # for r in range(nruns):
    #     for th in range(nthres):
    #         composite_relevances[r,th,:,:,:] = relevances[r,th].mean(0)
    
    # # Make a relevance plot
    # th      = 0
    # v       = 2
    # vmax    = 0.001
    
    # title   = "%s LRP Composites for %s, Prediction Lead = %i-yr" % (vnames[v],thresnames[th],lead)
    # fig,axs = plt.subplots(2,5,figsize=(16,6),
    #                        subplot_kw={'projection':proj},constrained_layout=True)
    
    # for r in range(nruns):
    #     ax      = axs.flatten()[r]
    #     plotvar = composite_relevances[r,th,v,:,:] 
    #     pcm     = ax.pcolormesh(lon,lat,plotvar,vmin=-vmax,vmax=vmax,cmap='RdBu_r')
    #     ax.coastlines()
    #     viz.label_sp(r+1,ax=ax,usenumber=True,labelstyle="Model %s")
        
    # cb = fig.colorbar(pcm,ax=axs.flatten(),fraction=0.045,orientation='horizontal')
    # cb.set_label("Relevance")
    # plt.suptitle(title)
    # plt.show()
    
    
    #%%
    
    """
    # Confusion Matrix based composites
    
    Make composites based on a given quadrant of the confusion matrix
    List the accuracy of each model run...
    """
    
    if plot_composites:
        # Chose which to plot
        #v       = 0 # variable
        #th      = 0 # class
        c       = 2 # confmat id
        vmax    = 0.001
        
        clvls   = np.arange(-0.5,.505,0.05)
        
        var_clvls = (np.arange(-0.5,.505,0.05), # SST
                     np.arange(-0.5,.505,0.05),
                     np.arange(-0.5,.505,0.05)
                     )
        
        for th in range(3):
        
            for v in tqdm(range(nvar)):
                
                clvls = var_clvls[v]
                title   = "Normalized %s LRP Composites for %s (%s), %i-yr Lead" % (vnames[v],thresnames[th],cmnames_long[c],lead)
                fig,axs = plt.subplots(2,5,figsize=(16,6),
                                       subplot_kw={'projection':proj},constrained_layout=True)
                
                for r in range(nruns):
                    ax      = axs.flatten()[r]
                    
                    # Index the variable, make the composites
                    id_sel      = cmids_all[r][th,c,:].astype(bool) # [nsamples]
                    plotvar     = X[id_sel,v,:,:].mean(0) * mask
                    plotrel     = relevances[r,th][id_sel[ids[r,th]],v,:,:].mean(0)
                    
                    # Scale relevance
                    if scale_relevance:
                        plotrel = plotrel / np.max(np.abs(plotrel))
                        vmax = 1
                    
                    # Calculate True Positive Rate
                    TP,FP,FN,TN = cmcounts_all[r][th,:]
                    plotacc     = TP / (TP+FN)
                    
                    # Make label for subplot
                    axlabel     = "FNN%02i (TPR=%.02f" % (r+1,plotacc*100) + "%)"
                    
                    # Actually plot the thing
                    if clvls is None:
                        cl      = ax.contour(lon,lat,plotvar,colors="k",linewidths=0.75)
                        ax.clabel(cl,fontsize=10)
                    else:
                        cl      = ax.contour(lon,lat,plotvar,colors="k",linewidths=0.75,levels=clvls)
                        ax.clabel(cl,levels=clvls[::2],fontsize=10,)
                    pcm     = ax.pcolormesh(lon,lat,plotrel,vmin=-vmax,vmax=vmax,cmap='RdBu_r',alpha=0.8)
                    
                    ax.coastlines()
                    viz.label_sp(axlabel,ax=ax,usenumber=True,labelstyle="%s",fontsize=10,alpha=0.7)
                    
                cb = fig.colorbar(pcm,ax=axs.flatten(),fraction=0.065,orientation='horizontal')
                cb.set_label("Relevance")
                cb.ax.xaxis.set_major_formatter(tick.FormatStrFormatter('%.2e'))
                
                plt.suptitle(title)
                #plt.show()
                
                figname = "%sFNN2_LRP_%scomposite_allruns_%s_%s_lead%02i.png" % (figpath,cm_names[c],thresnames[th],vnames[v],lead)
                plt.savefig(figname,dpi=150,bbox_inches='tight')

#%% Make simple composites N leads away from an AMV event



#%%



# #%% Plot 10 random samples for the above

# fig,axs = plt.subplots(5,10,figsize=(16,6),
#                        subplot_kw={'projection':proj},constrained_layout=True)


# clvls   = np.arange(-1,1.1,.1)#var_clvls[c]
# title   = "Normalized %s LRP for %s (%s), %i-yr Lead" % (vnames[v],thresnames[th],cmnames_long[c],lead)


# for r in range(nruns):
    
#     # Index the variable, make the composites
#     id_sel      = cmids_all[r][th,c,:].astype(bool) # [nsamples]
#     selvar     = X[id_sel,v,:,:] * mask
#     selrel     = relevances[r,th][id_sel[ids[r,th]],v,:,:]
    
    
#     rand_ids = np.random.choice(np.arange(0,plotrel.shape[0]),5)
#     ori_ids  = ids[r,th][id_sel[ids[r,th]]][rand_ids] # Get Original indices
    
#     ori_ens,ori_yr = np.unravel_index(ori_ids,(ens,tstep-lead))
#     ori_yr += 1920
#     for isample in range(5):
        
#         ax = axs[isample,r]
        
#         if isample == 0:
#             ax.set_title("FNN %02i" % (r+1))
        
#         # if r == 0:
#         #     ax.text(-0.05, 0.55, "i="ori_ids[isample], va='bottom', ha='center',rotation='vertical',
#         #         rotation_mode='anchor',transform=ax.transAxes)
        
#         axlabel = "ens%02i,yr=%i" % (ori_ens[isample],ori_yr[isample])
#         viz.label_sp(axlabel,ax=ax,usenumber=True,labelstyle="%s",fontsize=8,alpha=0.7,
#                      x=-.1,y=1.05)
        
        
#         plotvar = selvar[ori_ids[isample],:,:]
#         plotrel = selrel[ori_ids[isample],:,:]
        
#         # Actually plot the thing
#         if clvls is None:
#             cl      = ax.contour(lon,lat,plotvar,colors="k",linewidths=0.75)
#             ax.clabel(cl,fontsize=10)
#         else:
#             cl      = ax.contour(lon,lat,plotvar,colors="k",linewidths=0.75,levels=clvls)
#             ax.clabel(cl,levels=clvls[::2],fontsize=10,)
#         pcm     = ax.pcolormesh(lon,lat,plotrel,vmin=-vmax,vmax=vmax,cmap='RdBu_r',alpha=0.8)
        
#         #ax.set_extent([-80,0,0,65])
#         ax.coastlines()
        
# cb = fig.colorbar(pcm,ax=axs.flatten(),fraction=0.065,orientation='horizontal')
# cb.set_label("Relevance")
# cb.ax.xaxis.set_major_formatter(tick.FormatStrFormatter('%.2e'))
# plt.suptitle(title)
# plt.show()

