{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'CNN2'\n",
    "invar = 'ALL'\n",
    "channels = 3\n",
    "resolution = '2deg'\n",
    "indexregion = 'NAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_layerdims(nx,ny,filtersizes,filterstrides,poolsizes,poolstrides,nchannels):\n",
    "    \"\"\"\n",
    "    For a series of N convolutional layers, calculate the size of the first fully-connected \n",
    "    layer\n",
    "    \n",
    "    Inputs:\n",
    "        nx:           x dimensions of input\n",
    "        ny:           y dimensions of input\n",
    "        filtersize:   [ARRAY,length N] sizes of the filter in each layer [(x1,y1),[x2,y2]]\n",
    "        poolsize:     [ARRAY,length N] sizes of the maxpooling kernel in each layer\n",
    "        nchannels:    [ARRAY,] number of out_channels in each layer\n",
    "    output:\n",
    "        flattensize:  flattened dimensions of layer for input into FC layer\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # # ## Debug entry\n",
    "    # # 2 layer CNN settings \n",
    "    # nchannels     = [32,64]\n",
    "    # filtersizes   = [[2,3],[3,3]]\n",
    "    # filterstrides = [[1,1],[1,1]]\n",
    "    # poolsizes     = [[2,3],[2,3]]\n",
    "    # poolstrides   = [[2,3],[2,3]]\n",
    "    # nx = 33\n",
    "    # ny = 41\n",
    "    # # # ----\n",
    "    \n",
    "    \n",
    "    N = len(filtersizes)\n",
    "    xsizes = [nx]\n",
    "    ysizes = [ny]\n",
    "    fcsizes  = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        xsizes.append(np.floor((xsizes[i]-filtersizes[i][0])/filterstrides[i][0])+1)\n",
    "        ysizes.append(np.floor((ysizes[i]-filtersizes[i][1])/filterstrides[i][1])+1)\n",
    "        \n",
    "        \n",
    "        xsizes[i+1] = np.floor((xsizes[i+1] - poolsizes[i][0])/poolstrides[i][0]+1)\n",
    "        ysizes[i+1] = np.floor((ysizes[i+1] - poolsizes[i][1])/poolstrides[i][1]+1)\n",
    "        \n",
    "        fcsizes.append(np.floor(xsizes[i+1]*ysizes[i+1]*nchannels[i]))\n",
    "    \n",
    "    return int(fcsizes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_AMV_index(region,invar,lat,lon):\n",
    "    \"\"\"\n",
    "    Select bounding box for a given AMV region for an input variable\n",
    "        \"SPG\" - Subpolar Gyre\n",
    "        \"STG\" - Subtropical Gyre\n",
    "        \"TRO\" - Tropics\n",
    "        \"NAT\" - North Atlantic\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    region : STR\n",
    "        One of following the 3-letter combinations indicating selected region\n",
    "        (\"SPG\",\"STG\",\"TRO\",\"NAT\")\n",
    "        \n",
    "    var : ARRAY [Ensemble x time x lat x lon]\n",
    "        Input Array to select from\n",
    "    lat : ARRAY\n",
    "        Latitude values\n",
    "    lon : ARRAY\n",
    "        Longitude values    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    amv_index [ensemble x time]\n",
    "        AMV Index for a given region/variable\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select AMV Index region\n",
    "    bbox_SP = [-60,-15,40,65]\n",
    "    bbox_ST = [-80,-10,20,40]\n",
    "    bbox_TR = [-75,-15,0,20]\n",
    "    bbox_NA = [-80,0 ,0,65]\n",
    "    regions = (\"SPG\",\"STG\",\"TRO\",\"NAT\")        # Region Names\n",
    "    bboxes = (bbox_SP,bbox_ST,bbox_TR,bbox_NA) # Bounding Boxes\n",
    "    \n",
    "    # Get bounding box\n",
    "    bbox = bboxes[regions.index(region)]\n",
    "    \n",
    "    # Select Region\n",
    "    selvar = invar.copy()\n",
    "    klon = np.where((lon>=bbox[0]) & (lon<=bbox[1]))[0]\n",
    "    klat = np.where((lat>=bbox[2]) & (lat<=bbox[3]))[0]\n",
    "    print(selvar[:,klat[:,None],klon[None,:]])\n",
    "    selvar = selvar[:,klat[:,None],klon[None,:]]\n",
    "    \n",
    "    # Take mean ove region\n",
    "    amv_index = np.nanmean(selvar,(1,2))\n",
    "    \n",
    "    return amv_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = xr.open_dataset('../../CESM_data/HadISST_sst_NAtl_18700101_20181201_Regridded2deg.nc')\n",
    "sss = xr.open_dataset('../../CESM_data/CGLORSv5_sss_NAtl_19800115_20160101_Regridded2deg.nc')\n",
    "psl = xr.open_dataset('../../CESM_data/NOAA20CR_psl_NAtl_18510101_20141201_Regridded2deg.nc')\n",
    "\n",
    "sst = sst.groupby('time.year').mean()\n",
    "sss = sss.groupby('time.year').mean()\n",
    "psl = psl.groupby('time.year').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst_normed = ((sst - sst.mean())/sst.std())['sst'][1980-1870:-2018+2014,0:33,5:46]\n",
    "\n",
    "sss_normed = ((sss - sss.mean())/sss.std())['sss'][:-2016+2014,0:33,5:46]\n",
    "\n",
    "psl_normed = ((psl - psl.mean())/psl.std())['psl'][1980-1851:,0:33,5:46]\n",
    "\n",
    "sst_normed_full = ((sst - sst.mean())/sst.std())['sst'][1980-1870:-2018+2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lat/lon\n",
    "lon = np.load(\"../../CESM_data/lon_%s_NAT.npy\"%(resolution))\n",
    "lat = np.load(\"../../CESM_data/lat_%s_NAT.npy\"%(resolution))\n",
    "tstep,nlat,nlon = sst_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nchannels     = [32,64]\n",
    "filtersizes   = [[2,3],[3,3]]\n",
    "filterstrides = [[1,1],[1,1]]\n",
    "poolsizes     = [[2,3],[2,3]]\n",
    "poolstrides   = [[2,3],[2,3]]\n",
    "firstlineardim = calc_layerdims(nlat,nlon,filtersizes,filterstrides,poolsizes,poolstrides,nchannels)\n",
    "layers  = [\n",
    "            nn.Conv2d(in_channels=channels, out_channels=nchannels[0], kernel_size=filtersizes[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=poolsizes[0]),\n",
    "\n",
    "            nn.Conv2d(in_channels=nchannels[0], out_channels=nchannels[1], kernel_size=filtersizes[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=poolsizes[1]),            \n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=firstlineardim,out_features=64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features=64,out_features=1)\n",
    "          ]\n",
    "model = nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Unlabeled multi-dimensional array cannot be used for indexing: lat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-cf630ef19cbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_AMV_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexregion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msst_normed_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-e7f990949fee>\u001b[0m in \u001b[0;36mcalc_AMV_index\u001b[0;34m(region, invar, lat, lon)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mklon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlon\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlon\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mklat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mklat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mklon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mselvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mklat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mklon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.8/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# xarray-style array indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_key_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.8/site-packages/xarray/core/dataarray.py\u001b[0m in \u001b[0;36misel\u001b[0;34m(self, indexers, drop, missing_dims, **indexers_kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_fancy_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m             ds = self._to_temp_dataset()._isel_fancy(\n\u001b[0m\u001b[1;32m   1040\u001b[0m                 \u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmissing_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_isel_fancy\u001b[0;34m(self, indexers, drop, missing_dims)\u001b[0m\n\u001b[1;32m   2000\u001b[0m         \u001b[0;31m# Note: we need to preserve the original indexers variable in order to merge the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;31m# coords below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m         \u001b[0mindexers_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_indexers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.8/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m_validate_indexers\u001b[0;34m(self, indexers, missing_dims)\u001b[0m\n\u001b[1;32m   1833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m                     raise IndexError(\n\u001b[0m\u001b[1;32m   1836\u001b[0m                         \u001b[0;34m\"Unlabeled multi-dimensional array cannot be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m                         \u001b[0;34m\"used for indexing: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Unlabeled multi-dimensional array cannot be used for indexing: lat"
     ]
    }
   ],
   "source": [
    "y = calc_AMV_index(indexregion,sst_normed_full[lead:,:,:],lat,lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy( X[0:int(np.floor(percent_train*(tstep-lead)*ens)),:,:,:] )\n",
    "X_val = torch.from_numpy( X[int(np.floor(percent_train*(tstep-lead)*ens)):,:,:,:] )\n",
    "\n",
    "y_train = torch.from_numpy( y[0:int(np.floor(percent_train*(tstep-lead)*ens)),:] )\n",
    "y_val = torch.from_numpy( y[int(np.floor(percent_train*(tstep-lead)*ens)):,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=[2, 3], stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=[2, 3], stride=[2, 3], padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(32, 64, kernel_size=[3, 3], stride=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=[2, 3], stride=[2, 3], padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten()\n",
      "  (7): Linear(in_features=1344, out_features=64, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "path = '../../CESM_data/Models/'\n",
    "\n",
    "lead = 0\n",
    "\n",
    "for fname in os.listdir(path):\n",
    "    if 'lead'+str(lead) in fname and model_type in fname and invar in fname:\n",
    "        model.load_state_dict(torch.load(path+fname))\n",
    "        model.eval()\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
